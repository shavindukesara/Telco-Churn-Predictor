{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGzvaLjSu+IREQIaKVASHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shavindukesara/Telco-Churn-Predictor/blob/main/Telco%20Churn%20Predictor/source%20code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGtSMfsNtKdw",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# TELCO CUSTOMER CHURN PREDICTION\n",
        "# ================================================================================\n",
        "\n",
        "!pip install -q scikit-learn tensorflow pandas numpy matplotlib seaborn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_auc_score, roc_curve, auc)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# Load dataset from URL\n",
        "url = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(f\"Dataset loaded: {df.shape}\")\n",
        "print(df.head())\n",
        "\n",
        "# ================================================================================\n",
        "# EXPLORATORY DATA ANALYSIS (EDA)\n",
        "# ================================================================================\n",
        "\n",
        "# Basic Info\n",
        "print(\"\\n--- Dataset Info ---\")\n",
        "df.info()\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
        "\n",
        "# Target Variable Analysis\n",
        "print(\"\\n--- Target Variable Distribution ---\")\n",
        "print(df['Churn'].value_counts())\n",
        "print(f\"\\nChurn Rate: {df['Churn'].value_counts(normalize=True)['Yes']*100:.2f}%\")\n",
        "\n",
        "# Visualization 1: Churn Distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "churn_counts = df['Churn'].value_counts()\n",
        "axes[0].bar(churn_counts.index, churn_counts.values, color=['#2ecc71', '#e74c3c'])\n",
        "axes[0].set_title('Churn Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Count')\n",
        "for i, v in enumerate(churn_counts.values):\n",
        "    axes[0].text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "axes[1].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%',\n",
        "            startangle=90, colors=['#2ecc71', '#e74c3c'])\n",
        "axes[1].set_title('Churn Percentage', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInsight: Imbalanced dataset - 73% No Churn, 27% Churn\")\n",
        "\n",
        "# Numerical Features Analysis\n",
        "print(f\"\\nMissing values in TotalCharges before conversion: {df['TotalCharges'].isnull().sum()}\")\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "print(f\"Missing values in TotalCharges after conversion: {df['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# For EDA visualizations, use non-null values\n",
        "df_clean = df.dropna(subset=['TotalCharges'])\n",
        "\n",
        "# Update the histograms to use df_clean:\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "for idx, col in enumerate(['tenure', 'MonthlyCharges', 'TotalCharges']):\n",
        "    axes[idx].hist(df_clean[col], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "    axes[idx].set_title(f'{col} Distribution', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel(col)\n",
        "    axes[idx].set_ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 3: Numerical Features vs Churn\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "for idx, col in enumerate(['tenure', 'MonthlyCharges', 'TotalCharges']):\n",
        "    df.boxplot(column=col, by='Churn', ax=axes[idx], patch_artist=True,\n",
        "               boxprops=dict(facecolor='lightblue'),\n",
        "               medianprops=dict(color='red', linewidth=2))\n",
        "    axes[idx].set_title(f'{col} vs Churn', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Churn')\n",
        "    axes[idx].set_ylabel(col)\n",
        "    # Remove the automatic \"Boxplot grouped by Churn\" title\n",
        "    axes[idx].set_title(f'{col} Distribution by Churn', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.suptitle('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInsights:\")\n",
        "print(\"- Churned customers have lower tenure (shorter relationship)\")\n",
        "print(\"- Churned customers have higher monthly charges\")\n",
        "print(\"- Churned customers have lower total charges\")\n",
        "\n",
        "# Categorical Features Analysis\n",
        "# Visualization 4: Key Features vs Churn\n",
        "key_features = ['Contract', 'InternetService', 'PaymentMethod', 'OnlineSecurity']\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, feature in enumerate(key_features):\n",
        "    churn_data = pd.crosstab(df[feature], df['Churn'], normalize='index') * 100\n",
        "    churn_data.plot(kind='bar', ax=axes[idx], color=['#2ecc71', '#e74c3c'])\n",
        "    axes[idx].set_title(f'Churn Rate by {feature}', fontsize=11, fontweight='bold')\n",
        "    axes[idx].set_ylabel('Percentage (%)')\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "    axes[idx].legend(['No Churn', 'Churn'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Findings:\")\n",
        "print(\"- Month-to-month contracts: ~42% churn rate (HIGHEST)\")\n",
        "print(\"- Fiber optic internet: Higher churn rate\")\n",
        "print(\"- Electronic check payment: Higher churn rate\")\n",
        "print(\"- No online security: Higher churn rate\")\n",
        "\n",
        "# Correlation Analysis\n",
        "print(\"\\n--- Correlation Analysis ---\")\n",
        "df_corr = df.copy()\n",
        "\n",
        "# Encode categorical variables for correlation\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "if 'customerID' in categorical_cols:\n",
        "    categorical_cols.remove('customerID')\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_corr[col] = le.fit_transform(df_corr[col].astype(str))\n",
        "\n",
        "df_corr = df_corr.drop('customerID', axis=1)\n",
        "df_corr['TotalCharges'] = pd.to_numeric(df_corr['TotalCharges'], errors='coerce')\n",
        "df_corr['TotalCharges'] = df_corr['TotalCharges'].fillna(df_corr['TotalCharges'].median())\n",
        "\n",
        "correlation_matrix = df_corr.corr()\n",
        "\n",
        "# Top correlations with Churn\n",
        "corr_with_churn = correlation_matrix['Churn'].abs().sort_values(ascending=False)\n",
        "top_features = corr_with_churn.head(15).index.tolist()\n",
        "top_corr_matrix = correlation_matrix.loc[top_features, top_features]\n",
        "\n",
        "# Visualization 5: Top Features Correlation Heatmap with better colors\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(top_corr_matrix,\n",
        "            annot=True,\n",
        "            fmt='.2f',\n",
        "            cmap='RdYlBu_r',  # Better color scheme: Red-Yellow-Blue reversed\n",
        "            center=0,\n",
        "            square=True,\n",
        "            linewidths=0.5,\n",
        "            linecolor='white',\n",
        "            cbar_kws={'shrink': 0.8, 'label': 'Correlation'},\n",
        "            annot_kws={'size': 9, 'weight': 'bold'})\n",
        "\n",
        "plt.title('Top 15 Features Correlation Heatmap (with Churn)', fontsize=16, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "plt.yticks(rotation=0, fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "churn_corr = correlation_matrix['Churn'].abs().sort_values(ascending=False)\n",
        "print(\"\\nTop 15 Features Correlated with Churn:\")\n",
        "print(churn_corr[1:16])\n",
        "\n",
        "# Visualization 6: Tenure Groups Analysis\n",
        "tenure_bins = [0, 12, 24, 36, 48, 60, 72]\n",
        "df['TenureGroup'] = pd.cut(df['tenure'], bins=tenure_bins, labels=['0-12', '13-24', '25-36', '37-48', '49-60', '61-72'])\n",
        "tenure_churn = pd.crosstab(df['TenureGroup'], df['Churn'], normalize='index') * 100\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "tenure_churn.plot(kind='bar', color=['#2ecc71', '#e74c3c'])\n",
        "plt.title('Churn Rate by Tenure Groups', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Tenure (months)')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.legend(['No Churn', 'Churn'])\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInsight: Churn rate decreases significantly with tenure\")\n",
        "\n",
        "print(\"\"\"\n",
        "KEY FINDINGS:\n",
        "1. Dataset is imbalanced (73% No Churn, 27% Churn)\n",
        "2. Contract type is strongest predictor (month-to-month highest churn)\n",
        "3. Tenure inversely correlated with churn\n",
        "4. Monthly charges positively correlated with churn\n",
        "5. Internet service type and payment method affect churn\n",
        "6. Customers without add-on services churn more\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Handle missing values\n",
        "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
        "print(f\"Missing TotalCharges: {df_processed['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# direct assignment instead of inplace=True\n",
        "df_processed['TotalCharges'] = df_processed['TotalCharges'].fillna(df_processed['TotalCharges'].median())\n",
        "\n",
        "# Drop non-predictive columns\n",
        "df_processed = df_processed.drop(['customerID', 'TenureGroup'], axis=1, errors='ignore')\n",
        "\n",
        "# Encode binary variables\n",
        "binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "for col in binary_cols:\n",
        "    df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0})\n",
        "\n",
        "multi_class_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                    'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                    'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
        "df_processed = pd.get_dummies(df_processed, columns=multi_class_cols, drop_first=True, dtype=int)\n",
        "\n",
        "# Encode target\n",
        "df_processed['Churn'] = df_processed['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Separate features and target\n",
        "X = df_processed.drop('Churn', axis=1)\n",
        "y = df_processed['Churn']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(\"Preprocessing complete\")\n",
        "\n",
        "# =============================================================================\n",
        "# DECISION TREE MODEL\n",
        "# =============================================================================\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'max_depth': [4, 6, 8, 10, 12],\n",
        "    'min_samples_split': [10, 20, 30, 40],\n",
        "    'min_samples_leaf': [5, 10, 15, 20],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', 0.5, 0.7, None]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "dt_final = grid_search.best_estimator_\n",
        "y_pred_dt = dt_final.predict(X_test)\n",
        "y_pred_proba_dt = dt_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n--- DECISION TREE RESULTS ---\")\n",
        "print(classification_report(y_test, y_pred_dt, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "print(f\"Confusion Matrix:\\n{cm_dt}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['No Churn', 'Churn'],\n",
        "            yticklabels=['No Churn', 'Churn'])\n",
        "plt.ylabel('True Label', fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontweight='bold')\n",
        "plt.title('Confusion Matrix Heatmap - Decision Tree', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "dt_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
        "    'Precision': precision_score(y_test, y_pred_dt),\n",
        "    'Recall': recall_score(y_test, y_pred_dt),\n",
        "    'F1-Score': f1_score(y_test, y_pred_dt),\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_dt)\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in dt_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns.tolist(),\n",
        "    'Importance': dt_final.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(f\"\\nFeatures used (non-zero importance): {(feature_importance['Importance'] > 0).sum()}/{len(feature_importance)}\")\n",
        "print(f\"Sum of importances: {feature_importance['Importance'].sum():.6f}\")\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nContract Interpretation (baseline = Month-to-month):\")\n",
        "for feature in ['Contract_Two year', 'Contract_One year']:\n",
        "    if feature in feature_importance['Feature'].values:\n",
        "        imp = feature_importance.loc[feature_importance['Feature'] == feature, 'Importance'].values[0]\n",
        "        print(f\"  {feature}: {imp:.4f} (vs Month-to-month baseline)\")\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "top_n = min(15, len(feature_importance))\n",
        "top_features = feature_importance.head(top_n)\n",
        "\n",
        "colors = []\n",
        "for feature in top_features['Feature']:\n",
        "    if 'Contract' in feature:\n",
        "        colors.append('#e74c3c')\n",
        "    elif 'tenure' in feature.lower():\n",
        "        colors.append('#3498db')\n",
        "    elif 'charge' in feature.lower():\n",
        "        colors.append('#2ecc71')\n",
        "    else:\n",
        "        colors.append('#95a5a6')\n",
        "\n",
        "bars = plt.barh(range(top_n), top_features['Importance'], color=colors, edgecolor='black')\n",
        "\n",
        "for i, (imp, feature) in enumerate(zip(top_features['Importance'], top_features['Feature'])):\n",
        "    plt.text(imp + 0.001, i, f'{imp:.4f}', va='center', fontsize=9)\n",
        "\n",
        "plt.yticks(range(top_n), top_features['Feature'])\n",
        "plt.xlabel('Importance Score', fontweight='bold')\n",
        "plt.title(f'Top {top_n} Feature Importances - Decision Tree', fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_final, max_depth=3, feature_names=X_train.columns.tolist(),\n",
        "          class_names=['No Churn', 'Churn'], filled=True, rounded=True, fontsize=9)\n",
        "plt.title('Decision Tree (First 3 Levels)', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tree diagnostics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DECISION TREE DIAGNOSTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"Tree depth: {dt_final.get_depth()}\")\n",
        "print(f\"Number of leaves: {dt_final.get_n_leaves()}\")\n",
        "\n",
        "# Verify tree structure\n",
        "tree = dt_final.tree_\n",
        "feature_indices = tree.feature\n",
        "print(\"\\nFirst 5 splits in tree:\")\n",
        "for i in range(min(5, tree.node_count)):\n",
        "    if feature_indices[i] != -2:\n",
        "        feat_name = X_train.columns[feature_indices[i]]\n",
        "        threshold = tree.threshold[i]\n",
        "        print(f\"  Node {i}: {feat_name} <= {threshold:.4f}\")\n",
        "\n",
        "# Cross-check: Feature importance vs tree splits\n",
        "print(\"\\nCross-check - Features used in tree splits:\")\n",
        "used_features = []\n",
        "for i in range(tree.node_count):\n",
        "    if feature_indices[i] != -2:\n",
        "        feat_name = X_train.columns[feature_indices[i]]\n",
        "        if feat_name not in used_features:\n",
        "            used_features.append(feat_name)\n",
        "\n",
        "print(f\"Unique features in tree: {len(used_features)}\")\n",
        "print(\"Top features in tree:\")\n",
        "for feat in used_features[:5]:\n",
        "    print(f\"  â€¢ {feat}\")\n",
        "\n",
        "#Scaled vs Unscaled\n",
        "# =============================================================================\n",
        "# DECISION TREE ON SCALED DATA (Additional Model)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DECISION TREE ON SCALED DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train Decision Tree on scaled data using the same best parameters\n",
        "dt_scaled = DecisionTreeClassifier(\n",
        "    **grid_search.best_params_,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt_scaled = dt_scaled.predict(X_test_scaled)\n",
        "y_pred_proba_dt_scaled = dt_scaled.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n--- DECISION TREE ON SCALED DATA RESULTS ---\")\n",
        "print(classification_report(y_test, y_pred_dt_scaled, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "cm_dt_scaled = confusion_matrix(y_test, y_pred_dt_scaled)\n",
        "print(f\"Confusion Matrix:\\n{cm_dt_scaled}\")\n",
        "\n",
        "# Calculate metrics\n",
        "dt_scaled_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_dt_scaled),\n",
        "    'Precision': precision_score(y_test, y_pred_dt_scaled),\n",
        "    'Recall': recall_score(y_test, y_pred_dt_scaled),\n",
        "    'F1-Score': f1_score(y_test, y_pred_dt_scaled),\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_dt_scaled)\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in dt_scaled_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Visualization: Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_dt_scaled, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['No Churn', 'Churn'],\n",
        "            yticklabels=['No Churn', 'Churn'])\n",
        "plt.ylabel('True Label', fontweight='bold')\n",
        "plt.xlabel('Predicted Label', fontweight='bold')\n",
        "plt.title('Confusion Matrix Heatmap - Decision Tree (Scaled Data)', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance for scaled data tree\n",
        "feature_importance_scaled = pd.DataFrame({\n",
        "    'Feature': X_train.columns.tolist(),\n",
        "    'Importance': dt_scaled.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(f\"\\nFeatures used (non-zero importance) in scaled tree: {(feature_importance_scaled['Importance'] > 0).sum()}/{len(feature_importance_scaled)}\")\n",
        "\n",
        "print(\"\\nTop 10 Important Features (Scaled Data):\")\n",
        "print(feature_importance_scaled.head(10).to_string(index=False))\n",
        "\n",
        "# =============================================================================\n",
        "# ROC CURVES FOR BOTH DECISION TREES\n",
        "# =============================================================================\n",
        "\n",
        "#ROC curve for original Decision Tree\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# For original Decision Tree (raw data)\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_proba_dt)\n",
        "\n",
        "# For scaled Decision Tree\n",
        "fpr_dt_scaled, tpr_dt_scaled, _ = roc_curve(y_test, y_pred_proba_dt_scaled)\n",
        "\n",
        "# =============================================================================\n",
        "# COMPARISON: DECISION TREE ON RAW VS SCALED DATA\n",
        "# =============================================================================\n",
        "\n",
        "comparison_dt = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Decision Tree (Raw)': [dt_metrics['Accuracy'], dt_metrics['Precision'],\n",
        "                           dt_metrics['Recall'], dt_metrics['F1-Score'], dt_metrics['ROC-AUC']],\n",
        "    'Decision Tree (Scaled)': [dt_scaled_metrics['Accuracy'], dt_scaled_metrics['Precision'],\n",
        "                              dt_scaled_metrics['Recall'], dt_scaled_metrics['F1-Score'], dt_scaled_metrics['ROC-AUC']]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison_dt.to_string(index=False))\n",
        "\n",
        "# Visualization: Raw vs Scaled Decision Tree Comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart comparison\n",
        "x = np.arange(len(comparison_dt['Metric']))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = axes[0].bar(x - width/2, comparison_dt['Decision Tree (Raw)'], width,\n",
        "                    label='Decision Tree (Raw)', color='steelblue')\n",
        "bars2 = axes[0].bar(x + width/2, comparison_dt['Decision Tree (Scaled)'], width,\n",
        "                    label='Decision Tree (Scaled)', color='lightgreen')\n",
        "\n",
        "axes[0].set_xlabel('Metric', fontweight='bold')\n",
        "axes[0].set_ylabel('Score', fontweight='bold')\n",
        "axes[0].set_title('Decision Tree: Raw vs Scaled Data', fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(comparison_dt['Metric'])\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Feature importance comparison (top 10)\n",
        "top_n = 10\n",
        "top_raw = feature_importance.head(top_n)\n",
        "top_scaled = feature_importance_scaled.head(top_n)\n",
        "\n",
        "# Align features for comparison\n",
        "common_features = set(top_raw['Feature']).union(set(top_scaled['Feature']))\n",
        "importance_dict = {}\n",
        "for feat in common_features:\n",
        "    importance_dict[feat] = {\n",
        "        'Raw': top_raw.loc[top_raw['Feature'] == feat, 'Importance'].values[0]\n",
        "               if feat in top_raw['Feature'].values else 0,\n",
        "        'Scaled': top_scaled.loc[top_scaled['Feature'] == feat, 'Importance'].values[0]\n",
        "                 if feat in top_scaled['Feature'].values else 0\n",
        "    }\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict).T.sort_values('Raw', ascending=False)\n",
        "\n",
        "x_pos = np.arange(len(importance_df))\n",
        "axes[1].bar(x_pos - 0.2, importance_df['Raw'], 0.4, label='Raw Data', color='steelblue', alpha=0.8)\n",
        "axes[1].bar(x_pos + 0.2, importance_df['Scaled'], 0.4, label='Scaled Data', color='lightgreen', alpha=0.8)\n",
        "\n",
        "axes[1].set_xlabel('Features', fontweight='bold')\n",
        "axes[1].set_ylabel('Importance Score', fontweight='bold')\n",
        "axes[1].set_title('Top Feature Importance: Raw vs Scaled', fontweight='bold')\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(importance_df.index, rotation=45, ha='right')\n",
        "axes[1].legend()\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve comparison for raw vs scaled\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_dt, tpr_dt, linewidth=3, label=f'Decision Tree - Raw (AUC={dt_metrics[\"ROC-AUC\"]:.3f})')\n",
        "plt.plot(fpr_dt_scaled, tpr_dt_scaled, linewidth=3, label=f'Decision Tree - Scaled (AUC={dt_scaled_metrics[\"ROC-AUC\"]:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate', fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontweight='bold')\n",
        "plt.title('ROC Curve: Decision Tree on Raw vs Scaled Data', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# NEURAL NETWORK MODEL\n",
        "# =============================================================================\n",
        "\n",
        "# Calculating class weights\n",
        "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: class_weights_array[i] for i in range(len(class_weights_array))}\n",
        "print(f\"Class Weights: {class_weights}\")\n",
        "\n",
        "# Build model\n",
        "def create_nn_model(input_dim, learning_rate=0.001):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "print(\"\\nHyperparameter Tuning...\")\n",
        "configs = [\n",
        "    {'learning_rate': 0.001, 'batch_size': 32},\n",
        "    {'learning_rate': 0.0005, 'batch_size': 64},\n",
        "]\n",
        "\n",
        "best_score = 0\n",
        "best_config = None\n",
        "\n",
        "for config in configs:\n",
        "    print(f\"Testing LR={config['learning_rate']}, Batch={config['batch_size']}\")\n",
        "\n",
        "    model = create_nn_model(X_train_scaled.shape[1], config['learning_rate'])\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train,\n",
        "        epochs=30,\n",
        "        batch_size=config['batch_size'],\n",
        "        validation_split=0.2,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0)\n",
        "        ],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    _, _, val_auc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print(f\"  Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "    if val_auc > best_score:\n",
        "        best_score = val_auc\n",
        "        best_config = config\n",
        "        best_model = model\n",
        "\n",
        "print(f\"\\nBest Config: LR={best_config['learning_rate']}, Batch={best_config['batch_size']}\")\n",
        "\n",
        "# Train final model\n",
        "print(\"\\nTraining final model...\")\n",
        "nn_final = create_nn_model(X_train_scaled.shape[1], best_config['learning_rate'])\n",
        "\n",
        "history = nn_final.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=80,\n",
        "    batch_size=best_config['batch_size'],\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=15, min_delta=0.001, restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_pred_proba_nn = nn_final.predict(X_test_scaled).flatten()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_nn)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"\\nOptimal threshold: {optimal_threshold:.3f}\")\n",
        "\n",
        "y_pred_nn = (y_pred_proba_nn > optimal_threshold).astype(int)\n",
        "\n",
        "print(\"\\n--- NEURAL NETWORK RESULTS ---\")\n",
        "print(classification_report(y_test, y_pred_nn, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
        "print(f\"Confusion Matrix:\\n{cm_nn}\")\n",
        "\n",
        "nn_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_nn),\n",
        "    'Precision': precision_score(y_test, y_pred_nn),\n",
        "    'Recall': recall_score(y_test, y_pred_nn),\n",
        "    'F1-Score': f1_score(y_test, y_pred_nn),\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_nn)\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in nn_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Training History\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].plot(history.history['loss'], label='Train')\n",
        "axes[0].plot(history.history['val_loss'], label='Validation')\n",
        "axes[0].set_title('Loss', fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history.history['accuracy'], label='Train')\n",
        "axes[1].plot(history.history['val_accuracy'], label='Validation')\n",
        "axes[1].set_title('Accuracy', fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history.history['auc'], label='Train')\n",
        "axes[2].plot(history.history['val_auc'], label='Validation')\n",
        "axes[2].set_title('AUC', fontweight='bold')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve for Neural Network\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "         label=f'Neural Network ROC (AUC = {nn_metrics[\"ROC-AUC\"]:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100,\n",
        "            label=f'Optimal Threshold: {optimal_threshold:.3f}')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontweight='bold')\n",
        "plt.title('ROC Curve - Neural Network', fontweight='bold')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# MODEL COMPARISON\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Decision Tree': [dt_metrics['Accuracy'], dt_metrics['Precision'],\n",
        "                      dt_metrics['Recall'], dt_metrics['F1-Score'], dt_metrics['ROC-AUC']],\n",
        "    'Neural Network': [nn_metrics['Accuracy'], nn_metrics['Precision'],\n",
        "                       nn_metrics['Recall'], nn_metrics['F1-Score'], nn_metrics['ROC-AUC']]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualization: Metrics Comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "x = np.arange(len(comparison_df['Metric']))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = axes[0].bar(x - width/2, comparison_df['Decision Tree'], width,\n",
        "                    label='Decision Tree', color='steelblue')\n",
        "bars2 = axes[0].bar(x + width/2, comparison_df['Neural Network'], width,\n",
        "                    label='Neural Network', color='coral')\n",
        "\n",
        "axes[0].set_xlabel('Metric', fontweight='bold')\n",
        "axes[0].set_ylabel('Score', fontweight='bold')\n",
        "axes[0].set_title('Model Performance Comparison', fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(comparison_df['Metric'])\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Confusion Matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot Decision Tree Confusion Matrix\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['No Churn', 'Churn'],\n",
        "            yticklabels=['No Churn', 'Churn'])\n",
        "axes[0].set_title('Decision Tree - Confusion Matrix', fontweight='bold')\n",
        "axes[0].set_ylabel('True Label')\n",
        "axes[0].set_xlabel('Predicted Label')\n",
        "\n",
        "# Plot Neural Network Confusion Matrix\n",
        "sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
        "            xticklabels=['No Churn', 'Churn'],\n",
        "            yticklabels=['No Churn', 'Churn'])\n",
        "axes[1].set_title('Neural Network - Confusion Matrix', fontweight='bold')\n",
        "axes[1].set_ylabel('True Label')\n",
        "axes[1].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC Curves\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_proba_dt)\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_pred_proba_nn)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_dt, tpr_dt, linewidth=3, label=f'Decision Tree (AUC={dt_metrics[\"ROC-AUC\"]:.3f})')\n",
        "plt.plot(fpr_nn, tpr_nn, linewidth=3, label=f'Neural Network (AUC={nn_metrics[\"ROC-AUC\"]:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate', fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontweight='bold')\n",
        "plt.title('ROC Curve Comparison', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final Summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "winner = 'Neural Network' if nn_metrics['ROC-AUC'] > dt_metrics['ROC-AUC'] else 'Decision Tree'\n",
        "print(f\"\\nBest Model: {winner}\")\n",
        "print(f\"\\nDecision Tree - ROC-AUC: {dt_metrics['ROC-AUC']:.4f}\")\n",
        "print(f\"Neural Network - ROC-AUC: {nn_metrics['ROC-AUC']:.4f}\")\n",
        "\n"
      ]
    }
  ]
}