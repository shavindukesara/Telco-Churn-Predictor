{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOMng0/oG/XUWG+c/+fP5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shavindukesara/Telco-Churn-Predictor/blob/main/models/decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Handle missing values\n",
        "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
        "print(f\"Missing TotalCharges: {df_processed['TotalCharges'].isnull().sum()}\")\n",
        "\n",
        "# FIXED LINE: Use direct assignment instead of inplace=True\n",
        "df_processed['TotalCharges'] = df_processed['TotalCharges'].fillna(df_processed['TotalCharges'].median())\n",
        "\n",
        "# Drop non-predictive columns\n",
        "df_processed = df_processed.drop(['customerID', 'TenureGroup'], axis=1, errors='ignore')\n",
        "\n",
        "# Encode binary variables\n",
        "binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
        "for col in binary_cols:\n",
        "    df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0})\n",
        "\n",
        "# One-hot encode multi-class variables\n",
        "multi_class_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                    'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                    'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
        "df_processed = pd.get_dummies(df_processed, columns=multi_class_cols, drop_first=True, dtype=int)\n",
        "\n",
        "# Encode target\n",
        "df_processed['Churn'] = df_processed['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Separate features and target\n",
        "X = df_processed.drop('Churn', axis=1)\n",
        "y = df_processed['Churn']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(\"Preprocessing complete\")\n",
        "\n",
        "# Hyperparameter tuning\n",
        "print(\"\\nHyperparameter Tuning with GridSearchCV...\")\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Train final model\n",
        "dt_final = grid_search.best_estimator_\n",
        "y_pred_dt = dt_final.predict(X_test)\n",
        "y_pred_proba_dt = dt_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\n--- DECISION TREE RESULTS ---\")\n",
        "print(classification_report(y_test, y_pred_dt, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "print(f\"Confusion Matrix:\\n{cm_dt}\")\n",
        "\n",
        "dt_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
        "    'Precision': precision_score(y_test, y_pred_dt),\n",
        "    'Recall': recall_score(y_test, y_pred_dt),\n",
        "    'F1-Score': f1_score(y_test, y_pred_dt),\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_pred_proba_dt)\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in dt_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': dt_final.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance.head(10).to_string(index=False))\n",
        "\n",
        "# Visualize Feature Importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_15 = feature_importance.head(15)\n",
        "plt.barh(range(len(top_15)), top_15['Importance'], color='steelblue')\n",
        "plt.yticks(range(len(top_15)), top_15['Feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 15 Feature Importances - Decision Tree', fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize Tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_final, max_depth=3, feature_names=X.columns,\n",
        "          class_names=['No Churn', 'Churn'], filled=True, rounded=True, fontsize=9)\n",
        "plt.title('Decision Tree (First 3 Levels)', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DG6GP8peqzzq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}